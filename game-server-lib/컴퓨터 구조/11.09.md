CPU <-> 메모리 정보 교환이 오래걸림
CPU 내부의 코어와 물리적으로 매우 근접해서 빠른 정보 교환이 가능한 캐시를 사용
-> 빠르지만, 용량이 적다

캐시 철학
1. temporal locality -> 시간적으로 가장 최근에 추가된 데이터를 다시 이용할 확률이 높다.
2. spatial locality -> 공간적으로 보면 가장 추가된 데이터의 근처 데이터를 이용할 확률이 높다.

메모리 모델
CPU 연산 파이프라인에 따라서, 연산의 순서를 CPU 혹은 컴파일러가 임의로 수정 할 수있다. -> 하지만 이건 연산의 순서가 바뀌어도 결과가 동일하다는 가정 하에 가능.
즉, 싱글 스레드 환경에선 문제가 없지만, 멀티 스레드 환경에서는 연산 순서가 임의로 바뀌면 문제가 생길 수 있다.

atomic 연산
atomic 연산을 사용하면, 모든 스레드가 동일 객체에 대해서 동일한 수정 순서를 관찰 한다는 것을 보장 해 준다.
이 의미는, 어느 시점에 관찰을 하던, 동일한 순서로 관측이 가능하다는 것이다. (과거로의 관측은 불가능)
예를들어, atomic 객체의 값이 1 -> 2 -> 3 - > 4 의 순서로 변경 된다고 가정하자.
그럼 관찰자가 만약 1->2로 넘어 간 후에 객체를 관찰하면, 관찰자가 관찰 할 수 있는 객체의 값은 무조건 1 혹은 2이다. 캐시 메모리 혹은 다른 이유로 2로 값이 변경 되었다고 해도, 실제 객체 값은 관찰자가 관찰 할 때 여전히 1 일수도 있다.
-> 여기서 의미하는 atomic 연산이란, atomic 객체 뿐만 아니라, 한번에 발생하는 연산도 의미한다. 이는 CPU 상대적이다. 대입 연산과 같은 단순한 연산도, 64비트 환경에서는 한번의 연산만 하는 atomic 연산이 발생할 가능성이 높지만, 다른 컴퓨터에서는 추가적인 작업이 발생해서 atomic 연산이 아닐 가능성도 존재한다.

동일 객체에 한해서만 동일한 수정 순서 관찰이 보장된다. -> 다른 객체 두개의 수정 순서에 대해서는 순서를 보장 해 주지 않는다.

memory_order를 사용해 메모리 정책 변경 가능
1. Sequentially Consistent (seq_cst) 가장 엄격 = 최적화 여지가 적음 = 직관적 -> 가시성, 코드 재배치 문제 해결
2. Acquire-Release (acquire, release) 중간 단계 -> release 명령 이전의 코드들이 release 앞으로 재배치 되는것을 금지 시킴 또한 acquire를 기준으로 아래에 있는 코드들이 acquire 위로 올라가지 않도록 보장 ->  가시성 보장
3. Relaxed (relaxed) 지유롭다 = 컴파일러 최적화 여지가 많다 = 직관적이지 않다 -> 단일 객체에 대한 순서만 보장

대부분의 CPU는 순차적 실행을 보장한다. (ARM에선 성능 차이가 꽤 난다고함)09.2025

TLS (Thread Loacl Storage)
스레드 마다 가지고 있는 로컬 저장소
스택은 함수를 위한 메모리 공간 -> 불안정한 메모리 공간
TLS는 변수 보관 등에 쓸 수 있는 공간 -> 캐시같은 개념, 스레드 마다 존재하는 전역 메모리 같은 개념

LockStack
```cpp
#include <mutex>
template<typename T>
class LockStack {
public:
	LockStack(){}

	LockStack(const LockStack&) = delete;
	LockStack& operator=(const LockStack&) = delete;

	void Push(T value) {
		lock_guard<mutex> lock(_mutex);
		_queue.push(std::move(value));
		_conVar.notify_one();
	}

	bool TryPop(T& value) {
		lock_guard<mutex> lock(_mutex);
		if (_queue.empty()) {
			return false;
		}

		value = std::move(_queue.top());
		_queue.pop();
		return true;
	}

	bool WaitPop(T& value) {
		unique_lock<mutex> lock(_mutex);
		_conVar.wait(lock, [this]() { return !_queue.empty(); });
		value = std::move(_queue.top());
		_queue.pop();
		return true;
	}

private:
	queue<T> _queue;
	mutex _mutex;
	condition_variable _conVar;
};

```

LockQueue
```cpp
#pragma once
#include <mutex>

template<typename T>
class LockQueue {
public:
	LockQueue(){}

	LockQueue(const LockQueue&) = delete;
	LockQueue& operator=(const LockQueue&) = delete;

	void Push(T value) {
		lock_guard<mutex> lock(_mutex);
		_queue.push(std::move(value));
		_conVar.notify_one();
	}

	bool TryPop(T& value) {
		lock_guard<mutex> lock(_mutex);
		if (_queue.empty()) {
			return false;
		}
		value = std::move(_queue.front());
		_queue.pop();
		return true;
	}

	bool WaitPop(T& value) {
		unique_lock<mutex> lock(_mutex);
		_conVar.wait(lock, [this]() { return !_queue.empty(); });
		value = std::move(_queue.front());
		_queue.pop();
		return true;
	}

private:
	queue<T> _queue;
	mutex _mutex;
	condition_variable _conVar;
};

```
